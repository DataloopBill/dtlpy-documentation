{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## QA on Annotation Level  \n", "To reach the tasks and assignments repositories go to <a href=\"https://sdk-docs.dataloop.ai/en/latest/repositories.html#module-dtlpy.repositories.tasks\" target=\"_blank\">tasks</a> and <a href=\"https://sdk-docs.dataloop.ai/en/latest/repositories.html#module-dtlpy.repositories.assignments\" target=\"_blank\">assignments</a>.  \n", "  \n", "  \n", "To reach the tasks and assignments entities go to <a href=\"https://sdk-docs.dataloop.ai/en/latest/entities.html#module-dtlpy.entities.task\" target=\"_blank\">tasks</a> and <a href=\"https://sdk-docs.dataloop.ai/en/latest/entities.html#module-dtlpy.entities.assignment\" target=\"_blank\">assignments</a>.  \n", "### ItemAnnotations Review  \n", "The Annotation Studio also enables direct feedback for specific annotations. To enable a realtime review, a Reviewer can open an issue on an Annotation.  \n", "The Annotator (person who annotated the issued Annotation) then receives the issue, fixes it and sends it back for a second review.  \n", "The Reviewer may approve the fix or return it as an issue.  \n", "  \n", "We also support a real-time dialog on items as an annotation, go to <a href=\"https://dataloop.ai/docs/note-annotation\" target=\"_blank\">Note Annotation</a> to learn more.  \n", "#### Prep  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "if dl.token_expired():\n", "    dl.login()\n", "project = dl.projects.get(project_name='project_name')\n", "dataset = project.datasets.get(dataset_name='dataset_name')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Single status update  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Mark a single annotation with an open issue\n", "item = dataset.items.get(item_id='my-item-id')\n", "annotation = item.annotations.get(annotation_id='your-annotation-id-number')\n", "annotation.update_status(dl.AnnotationStatus.ISSUE)\n", "# In the same way you can update to another status\n", "annotation.update_status(dl.AnnotationStatus.APPROVED)\n", "annotation.update_status(dl.AnnotationStatus.REVIEW)\n", "annotation.update_status(dl.AnnotationStatus.CLEAR) # Have the annotation without status\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Bulk status update  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Get Task\n", "task = project.tasks.get(task_id='my_task_id')\n", "#Add filters for items in the task who have annotations with issues\n", "filters = dl.Filters()\n", "filters.add_join(field='metadata.system.status', values='issue')\n", "items = task.get_items(filters=filters)\n", "#Go over all of the items\n", "for page in items:\n", "    for item in page:\n", "        #Add filter for annotations with issues\n", "        filters = dl.Filters()\n", "        filters.resource = dl.FiltersResource.ANNOTATION\n", "        filters.add(field='metadata.system.status', values='issue')\n", "        annotations = item.annotations.list(filters=filters)\n", "        #For every annotation that has issue in the item update the status to \"for review\"\n", "        for annotation in annotations:           annotation.update_status(dl.AnnotationStatus.REVIEW)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}