{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Task Assignment  \n", "To reach the tasks and assignments repositories go to <a href=\"https://sdk-docs.dataloop.ai/en/latest/repositories.html#module-dtlpy.repositories.tasks\" target=\"_blank\">tasks</a> and <a href=\"https://sdk-docs.dataloop.ai/en/latest/repositories.html#module-dtlpy.repositories.assignments\" target=\"_blank\">assignments</a>.  \n", "  \n", "  \n", "To reach the tasks and assignments entities go to <a href=\"https://sdk-docs.dataloop.ai/en/latest/entities.html#module-dtlpy.entities.task\" target=\"_blank\">tasks</a> and <a href=\"https://sdk-docs.dataloop.ai/en/latest/entities.html#module-dtlpy.entities.assignment\" target=\"_blank\">assignments</a>.  \n", "### Item Review  \n", "The Annotation Studio is built for realtime review, task assignment and feedback.  \n", "  \n", "Each item can be classified in 3 ways:  \n", "* **Discarded**: Items that are not relevant for labeling  \n", "* **Complete** (or an alternate custom status created by the task creator): Items after an annotation process  \n", "* **Approved** (or an alternate custom status created by the task creator): Completed items after a QA process  \n", "#### Prep  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "if dl.token_expired():\n", "    dl.login()\n", "project = dl.projects.get(project_name='<project_name>')\n", "dataset = project.datasets.get(dataset_name='<dataset_name>')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Single status update  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Mark single item as completed\n", "item = dataset.items.get(item_id='<my-item-id>')\n", "item.update_status(status=dl.ItemStatus.COMPLETED)\n", "# In the same way you can update to another status\n", "item.update_status(status=dl.ItemStatus.APPROVED)\n", "item.update_status(status=dl.ItemStatus.DISCARDED)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Clear status  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Clear status for completed/approved/discarded\n", "item.update_status(dl.ITEM_STATUS_COMPLETED, clear=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Bulk status update  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# With items list\n", "filters = dl.Filters(field='<annotated>', values=True)\n", "items = dataset.items.list(filters=filters)\n", "dataset.items.update_status(status=dl.ItemStatus.APPROVED, items=items)\n", "# With filters\n", "filters = dl.Filters(field='<annotated>', values=True)\n", "dataset.items.update_status(status=dl.ItemStatus.DISCARDED, filters=filters)\n", "# With list of item ids\n", "item_ids = ['<id1>', '<id2>', '<id3>']\n", "dataset.items.update_status(status=dl.ItemStatus.COMPLETED, item_ids=item_ids)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["####    Example  \n", "To mark an entire task as completed use the following:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["task = dataset.tasks.get(task_name='<my-task-name>')\n", "dataset.items.update_status(status=dl.ItemStatus.COMPLETED, items=task.get_items())\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}