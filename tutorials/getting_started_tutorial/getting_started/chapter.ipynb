{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Getting Started  \n", "## Installations and environment creation:  \n", "### Install Python  \n", "Python version 3.6 to 3.9 needs to be installed on your system using this official website. Earlier or later versions are not supported.  \n", "  \n", "### Install the dtlpy package  \n", "Install the plugin using pip, write the following command and press ENTER:  \n", "Please make sure you have pip installed on your computer (you can verify this by typing the command 'pip help' in your terminal); otherwise, download pip.  \n", "pip install dtlpy  \n", "  \n", "Alternatively, install pip from the source by cloning the GitHub repo, then run the following command:  \n", "python setup.py install  \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Login  \n", "To log in, type the command below :  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["dl.login()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Since the login token expires after 24 hours,you can add this to the beginning of your python script :  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["if dl.token_expired():\n", "    dl.login()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once your browser opens the Login  screen, type the credentials below or login with Google.  \n", "Please wait for the \"Login Successful\" tab to appear, then close the tab.  \n", "  \n", "## M2M Login  \n", "Long-running SDK jobs require API authentication.  \n", "The M2M flow allows machines to obtain valid, signed JWT (authentication token) and automatically refresh it, without the need for a real user account UI login.  \n", "  \n", "M2M Login is recommended when you want to:  \n", "    - run commands on the platform without an ongoing internet connection  \n", "    - run API commands directly from an external system to Dataloop  \n", "  \n", "## Log In Via SDK with M2M :  \n", "1. Create a bot user with a unique name:  \n", "Create a bot user with developer permissions to be used for every M2M login.  \n", "You only need to perform this step if this is your first time logging in.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "# use browser login to create the bot\n", "dl.login()\n", "project = dl.projects.get(project_name='myProject')  # get your project\n", "my_bot = project.bots.create(name='my-unique-name', return_credentials=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now make sure to save the bot's email and password for future logins:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["print(\"the bot email is \" + my_bot.email)\n", "print(\"the bot password is \" + my_bot.password)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["2. Log in to the SDK with your new bot:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "# Login to Dataloop platform\n", "dl.login_m2m(email=email, password=password)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create & Get a Project  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["project = dl.projects.create(project_name='my-new-project')\n", "project = dl.projects.get(project_name='my-project')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create & Get a Dataset  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["project.datasets.create(dataset_name='my-dataset-name')\n", "dataset = project.datasets.get(dataset_name='my-dataset-name')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Upload items  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["dataset.items.upload(local_path=\"/path/to/image.jpg\")\n", "# Upload items to a specific folder in the dataset\n", "dataset.items.upload(local_path=\"/path/to/image.jpg\", remote_path=\"/path/to/dataset/folder\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Get Item / items-list  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Get a single item\n", "item = dataset.items.get(item_id='my_item_Id')\n", "", "# Get all items and iterate through them\n", "pages = dataset.items.list()\n", "# Go over all item and print the properties\n", "for page in pages:\n", "    for item in page:\n", "        item.print()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Filters includes join and all operations  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Filter all items with an annotation that has a label in the list\n", "filters = dl.Filters()\n", "# Filter items with dog OR cat labels\n", "filters.add_join(field='label', values=['dog', 'cat'], operator=dl.FILTERS_OPERATIONS_IN)\n", "# optional - return results sorted by ascending file name\n", "filters.sort_by(field='filename')\n", "# Get filtered items list in a page object\n", "pages = dataset.items.list(filters=filters)\n", "# Count the items\n", "print('Number of items in dataset: {}'.format(pages.items_count))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Add metadata to the item  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item.metadata['user'] = dict()\n", "item.metadata['user']['MyKey'] = 'MyValue'\n", "item.update()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Upload annotations (with Dataloop Builder)  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Upload box annotation\n", "builder.add(annotation_definition=dl.Box(top=10, left=10, bottom=100, right=100, label='labelName'))\n", "item.annotations.upload(builder)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Upload segmentation annotation  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["mask = np.zeros(shape=(item.height, item.width), dtype=np.uint8)\n", "mask[50:100, 200:250] = builder.add(annotation_definition=dl.Segmentation(geo=mask, label='label1'))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Get annotations + list (pages)  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# getting the item\n", "item = dl.items.get(item_id='item_id')\n", "# now getting the items annotations list\n", "for ann in item.annotations.list():\n", "    print(ann)\n", "", "# we can also get only annotated items from a dataset then print out the annotations that were created by a\n", "# specific user.\n", "dataset = dl.datasets.get(dataset_id='dataset_id')\n", "# creating the annotated items filter\n", "ItemFilter = dl.Filters()\n", "ItemFilter.add(field='annotated', values=True)\n", "# creating the annotation level filter\n", "annotation_filter = dl.Filters(resource=dl.FiltersResource.ANNOTATION)\n", "annotation_filter.add(field='creator', values='sewar.d@dataloop.ai')\n", "pages = dataset.items.list(filters=ItemFilter)\n", "for page in pages:\n", "    for item in page:\n", "        for ann in item.annotations.list(annotation_filter):\n", "            print(ann)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Annotation update includes metadata  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["annotation.metadata['user'] = dict()\n", "annotation.metadata['user']['MyKey'] = 'MyValue'\n", "annotation.update()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## load annotations from JSON file  \n", "### Loading a COCO json :  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["path = r'path-to-json'\n", "converter = dl.Converter()\n", "converter.upload_local_dataset(\n", "    from_format=dl.AnnotationFormat.COCO,\n", "    dataset=dataset,\n", "    local_annotations_path=path)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Loading it based on your json format:  \n", "In this example we iterate over the json file,filter the item from the platform based on it\u2019s name,then update it\u2019s metadata and upload annotations.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["path = r'path-to-json'\n", "ds = dl.datasets.get(dataset_id='ds_ID')\n", "# load the json\n", "with open(json_path, 'r', encoding=\"utf8\") as f:\n", "    data = json.load(f)\n", "    # filter the items in the dataset based on a key\\ID\\name..\n", "    namefilter = dl.Filters()\n", "    namefilter.resource = dl.FILTERS_RESOURCE_ITEM\n", "    namefilter.add(field='name', values=data['img_name'])\n", "    pages = dataset.items.list(filters=namefilter)\n", "    # pbar to track the progress\n", "    pbar = tqdm.tqdm(total=pages.items_count)\n", "    # going over the filter result\n", "    for page in pages:\n", "        for item in page:\n", "            # now updating the metadata\n", "            item.metadata['user'] = dict()\n", "            item.metadata['user']['camera_dict'] = data['camera_dict']\n", "            item.metadata['user']['name'] = data['name']\n", "            item.update()\n", "            # for the same item we'll update the annotations\n", "            for i_ann in range(len(data['annotations'])):\n", "                label = data['annotations'][i_ann]['object_type']\n", "                top = data['annotations'][i_ann]['top'][0]\n", "                left = data['annotations'][i_ann]['left'][0]\n", "                bottom = data['annotations'][i_ann]['bottom'][0]\n", "                right = data['annotations'][i_ann]['right'][1]\n", "                angle = data['annotations'][i_ann]['bbox_angle_deg']\n", "                builder.add(\n", "                    annotation_definition=dl.Box(top=top, left=left, bottom=bottom, right=right, label=label,\n", "                                                 angle=angle))\n", "                item.annotations.upload(builder)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Creating an annotation task and adding items to it  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["task = dataset.tasks.create(\n", "    task_name='task_name',\n", "    assignee_ids=['annotator1@dataloop.ai', 'annotator2@dataloop.ai'])\n", "", "filters = dl.Filters(field='dir', values='/my/folder/directory')\n", "task.add_items(\n", "    filters=filters, assignee_ids=['annotator1@dataloop.ai', 'annotator2@dataloop.ai'])\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}