{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Tutorial: Using models from the AI library  \n", "  \n", "Model algorithms that are ready for use out-of-the-box are available in the Dataloop AI Library. The AI library contains various algorithms and pretrained models that can be used for inferencing or fine-tuning via additional training on your custom datasets.  \n", "  \n", "This tutorial will cover how to use AI library models for:  \n", "  \n", "- predicting from pretrained models, and  \n", "- fine-tuning training on a custom dataset.  \n", "  \n", "To see available public models, filter all available packages to view those with a \u201cpublic\u201d scope:  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["filters = dl.Filters(resource=dl.FiltersResource.MODEL, use_defaults=False)\n", "filters.add(field='scope', values='public')\n", "dl.models.list(filters=filters).print()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Clone and deploy a public model  \n", "  \n", "Download the model and package you want to copy it to your project.  \n", "  \n", "Only models that are trained (i.e. model.status = 'trained') can be deployed. Since the public model is pre-trained, it can be deployed directly.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["public_model = dl.models.get(model_id=\"<model_id>\")\n", "", "model = project.models.clone(from_model=public_model,\n", "                             model_name='remote_model',\n", "                             project_id=project.id)\n", "", "model.deploy()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Train on a custom dataset  \n", "  \n", "If you want to customize the public model (for transfer-learning or fine-tuning), you can indicate the new dataset and labels you want to use for model training.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["custom_model = dl.models.clone(from_model=public_model,\n", "                               model_name='remote_custom_model',\n", "                               dataset=dataset,\n", "                               project_id=project.id,\n", "                               labels=['label1', 'label2'])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  \n", "#### Dataset Subsets  \n", "Our public models use a train/validation split of the dataset for the training session. To avoid data leakage between training sessions and to make each training reproducible,  \n", "we will determine the data subsets and save the split type to the dataset entity (using a DQL). Using DQL filters you can subset the data however you like.  \n", "  \n", "For example, if your dataset is split between folders, you can use this DQL to add metadata for all items in the dataset  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["dataset.metadata['system']['subsets'] = {\n", "    'train': json.dumps(dl.Filters(field='dir', values='/train').prepare()),\n", "    'validation': json.dumps(dl.Filters(field='dir', values='/validation').prepare()),\n", "}\n", "dataset.update(system_metadata=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This way, when the training starts, the sets will be downloaded using the DQL and any future training session on this dataset will have the same subsets of data.  \n", "  \n", "NOTE: In the future, this mechanism will be expanded to use a tagging system on items. This will allow more flexible data subsets and random data allocation.  \n", "  \n", "#### Deploying the model  \n", "  \n", "Once the model is trained, it can be deployed as a service. The `model.deploy()` function automatically creates a bot and service for the trained model.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["custom_model.train()\n", "custom_model.deploy()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have a model deployed, you can create a UI slot to inference on individual data items on the platform, or call the model to inference in a FaaS or pipelines.  \n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}