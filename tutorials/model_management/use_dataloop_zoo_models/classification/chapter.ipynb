{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Training a classification model with ResNet  \n", "In this tutorial we will use a publicly available model from the AI library to inference and train on custom data.  \n", "Here we will use the resnet model.  \n", "  \n", "Start by installing the following packages if you don't have them installed already (the Torch Model Adapter will use them later):  \n", "  \n", "torch  \n", "torchvision  \n", "imgaug  \n", "scikit-image<0.18  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# !pip install torch torchvision imgaug \"scikit-image<0.18\"\n", "import matplotlib.pyplot as plt\n", "from PIL import Image\n", "import numpy as np\n", "import dtlpy as dl\n", "from dtlpy.ml import train_utils\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create the Package and pretrained Model in your project  \n", "First, we create the entities for our project. The package codebase is available in the public Dataloop Github.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["package = dl.packages.get(package_name='resnet')\n", "model = package.models.get(model_name='pretrained-resnet50')\n", "package.models.list().to_df()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Run a pretrained model  \n", "We will \"build\" to model adapter to get the package code locally and create an instance of the ModelAdapter class.  \n", "Then we will load the pretrained model into the model adapter.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter = package.build()\n", "adapter.load_from_model(model=model)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Predict on an item  \n", "Now you can get an item and inference on it with predict with upload.  \n", "If you would like to see the item and predictions, you can open the item on the platform and edit there.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item = dl.items.get(item_id='611e174e4c09acc3c5bb81d3')\n", "annotations = adapter.predict_items([item], with_upload=True)\n", "", "image = np.asarray(Image.open(item.download()))\n", "plt.imshow(item.annotations.show(image,\n", "                                 thickness=5))\n", "print('Classification: {}'.format(annotations[0][0].label))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train on new dataset  \n", "Here we will use a public dataset of sheep faces. We create a project and a dataset and upload the data with 4 labels of sheep.  \n", "NOTE: You might need to change the location of the items (should point to the root of the documentation repository)  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["project = dl.projects.create('Sheep Face - Model Mgmt')\n", "dataset = project.datasets.create('Sheep Face')\n", "dataset.to_df()\n", "_ = dataset.items.upload(local_path='../../../../assets/sample_datasets/SheepFace/items/*',\n", "                         local_annotations_path='../../../../assets/sample_datasets/SheepFace/json')\n", "dataset.add_labels(label_list=['Merino', 'Poll Dorset', 'Suffolk', 'White Suffolk'])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we'll run the \"prepare_dataset\" method. This will clone and freeze the dataset so that we'll be able to reproduce the training with and keep the snapshot of the data.  \n", "The cloned dataset will be split into subsets, either filtered using DQL or as percentages. In this example, we'll use an 80/20 train validation split.  \n", "After partitioning the data, we will clone the pretrained model to have a starting point for the fine-tuning.  \n", "The model's configuration will determine some runtime configurations, such as number of epochs. In this tutorial we will train for only 2 epochs.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["partitions = {dl.DatasetSubsetType.TRAIN: 0.8,\n", "              dl.DatasetSubsetType.VALIDATION: 0.2}\n", "cloned_dataset = train_utils.prepare_dataset(dataset,\n", "                                             filters=None,\n", "                                             partitions=partitions)\n", "model_name = 'sheep-soft-augmentations'\n", "# create an Item Artifact to save the model to your project\n", "artifact = project.artifacts.create(artifact_type=dl.ArtifactType.ITEM,\n", "                                    package_name=package.name,\n", "                                    model_name=model_name)\n", "new_model = model.clone(model_name=model_name,\n", "                        dataset_id=cloned_dataset.id,\n", "                        project_id=project.id,\n", "                        artifact=artifact,\n", "                        labels=list(dataset.instance_map.keys()),\n", "                        configuration={'batch_size': 16,\n", "                                       'start_epoch': 0,\n", "                                       'num_epochs': 2,\n", "                                       'input_size': 256,\n", "                                       'id_to_label_map': {(v - 1): k for k, v in\n", "                                                           dataset.instance_map.items()}\n", "                                       })\n", "new_model = package.models.get(model_name=model_name)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll load the new, un-trained model into the adapter and prepare the training local dataset.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter.load_from_model(model=new_model)\n", "root_path, data_path, output_path = adapter.prepare_training()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Start the training  \n", "The package, model, and data are now prepared. We are ready to train!  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["print(\"Training {!r} with model {!r} on data {!r}\".format(package.name, new_model.id, data_path))\n", "", "adapter.train(data_path=data_path,\n", "              output_path=output_path)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Save the Model  \n", "We will save the locally-trained model and upload the trained weights to the Item Artifact.  \n", "This will ensure that everything is in the Dataloop platform and everyone can use our trained model.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter.save_to_model(local_path=output_path,\n", "                      replace=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can also list all our artifacts associated with this package, and add more files that are needed to load or run the model.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter.model.artifacts.list_content()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Predict on our newly trained model  \n", "With everything in place, we will load our model and view the item's prediction.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item = dl.items.get(item_id='611e174e4c09acc3c5bb81d3')\n", "annotations = adapter.predict_items([item], with_upload=True)\n", "image = Image.open(item.download())\n", "plt.imshow(item.annotations.show(np.asarray(image),\n", "                                 thickness=5))\n", "print('Classification: {}'.format(annotations[0][0].label))\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}