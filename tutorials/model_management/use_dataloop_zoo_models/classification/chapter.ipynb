{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classification model with ResNet  \n",
    "In this tutorial we will use the Resnet Model Adapter to inference and train on custom data.  \n",
    "If you don't have the following packages, you'll need to install. The Torch Model Adapter will use them later:  \n",
    "torch  \n",
    "torchvision  \n",
    "imgaug  \n",
    "scikit-image<0.18  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\shabtay\\fonda\\venv\\lib\\site-packages\\dtlpy\\services\\api_client.py:1193: DeprecationWarning: Using 'method_whitelist' with Retry is deprecated and will be removed in v2.0. Use 'allowed_methods' instead\n",
      "  raise_on_status=False\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import dtlpy as dl\n",
    "from dtlpy.ml import train_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Global Model and Pretrained Snapshot  \n",
    "We start by getting tne model and an ImageNet pretrained model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\shabtay\\fonda\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creator</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>is_global</th>\n",
       "      <th>status</th>\n",
       "      <th>tags</th>\n",
       "      <th>configuration</th>\n",
       "      <th>version</th>\n",
       "      <th>context</th>\n",
       "      <th>modelId</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>bucket</th>\n",
       "      <th>ontologySpec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616d70ed451677b35347ee34</td>\n",
       "      <td>yair@dataloop.ai</td>\n",
       "      <td>pretrained-resnet18</td>\n",
       "      <td>resnset18 pretrained on imagenet</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[pretrained, imagenet]</td>\n",
       "      <td>{'weights_filename': 'model.pth', 'classes_fil...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-10-18T13:04:45.480Z</td>\n",
       "      <td>{'type': 'gcs', 'gcsProjectName': 'viewo-main'...</td>\n",
       "      <td>{'labels': ['tench', 'goldfish', 'great white ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6280bde54b152c24a698ee26</td>\n",
       "      <td>or@dataloop.ai</td>\n",
       "      <td>sheep-soft-augmentations</td>\n",
       "      <td>resnset18 pretrained on imagenet</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[pretrained, imagenet]</td>\n",
       "      <td>{'weights_filename': 'model.pth', 'classes_fil...</td>\n",
       "      <td>1.0.1</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>6280bda5ea2a6ca88830589b</td>\n",
       "      <td>2021-10-18T13:04:45.480Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '6280bde4c31b850518...</td>\n",
       "      <td>{'labels': ['tench', 'goldfish', 'great white ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>616d70f37136cad9e8a78ad7</td>\n",
       "      <td>yair@dataloop.ai</td>\n",
       "      <td>pretrained-resnet50</td>\n",
       "      <td>resnset50 pretrained on imagenet</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[pretrained, imagenet]</td>\n",
       "      <td>{'weights_filename': 'model.pth', 'classes_fil...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-10-18T13:04:51.467Z</td>\n",
       "      <td>{'type': 'gcs', 'gcsProjectName': 'viewo-main'...</td>\n",
       "      <td>{'labels': ['tench', 'goldfish', 'great white ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>616ef7be950f5dccfc9e57b8</td>\n",
       "      <td>pipelines-reg@dataloop.ai</td>\n",
       "      <td>resnet18-label-sug-pretrained-recipe-60350315b...</td>\n",
       "      <td>resnset18 pretrained on imagenet</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[pretrained, imagenet]</td>\n",
       "      <td>{'weights_filename': 'model.pth', 'classes_fil...</td>\n",
       "      <td>1.0.1</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-10-19T16:52:14.537Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '616ef7be930c82bada...</td>\n",
       "      <td>{'labels': ['tench', 'goldfish', 'great white ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>616ef943950f5d2c659e57ba</td>\n",
       "      <td>pipelines-reg@dataloop.ai</td>\n",
       "      <td>resnet18-label-sug-pretrained-recipe-616be3db4...</td>\n",
       "      <td>resnset18 pretrained on imagenet</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[pretrained, imagenet]</td>\n",
       "      <td>{'weights_filename': 'model.pth', 'classes_fil...</td>\n",
       "      <td>1.0.1</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-10-19T16:58:43.796Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '616ef943930c82bada...</td>\n",
       "      <td>{'labels': ['tench', 'goldfish', 'great white ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>621e24afa7c041a172862d7c</td>\n",
       "      <td>pipelines@dataloop.ai</td>\n",
       "      <td>resnet18-label-sug-pretrained-recipe-621e2319c...</td>\n",
       "      <td>My snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[label-suggest]</td>\n",
       "      <td>{'batch_size': 16, 'start_epoch': 0, 'num_epoc...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-03-01T13:50:39.909Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '621e249b4aa3db5d7e...</td>\n",
       "      <td>{'labels': [], 'ontologyId': 'null'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>621e3948a7c04117cd862d84</td>\n",
       "      <td>pipelines@dataloop.ai</td>\n",
       "      <td>resnet18-label-sug-pretrained-recipe-621e391d8...</td>\n",
       "      <td>My snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[label-suggest]</td>\n",
       "      <td>{'batch_size': 16, 'start_epoch': 0, 'num_epoc...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-03-01T15:18:32.709Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '621e39391bdd033c7f...</td>\n",
       "      <td>{'labels': ['Test', 'Test2'], 'ontologyId': 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>624ecd80c7e35d6ff5e24d21</td>\n",
       "      <td>pipelines@dataloop.ai</td>\n",
       "      <td>resnet18-label-sug-pretrained-recipe-61dc00b54...</td>\n",
       "      <td>My snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[label-suggest]</td>\n",
       "      <td>{'batch_size': 16, 'start_epoch': 0, 'num_epoc...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>{'org': '7db04660-d106-4ec2-879e-ba48fb0ca2b0'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-04-07T11:39:44.694Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '624ecd70c07eba9a96...</td>\n",
       "      <td>{'labels': ['dog', 'eye', 'as', 's', 'aaaaaaa'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>625d8032ff09e1357a3ad057</td>\n",
       "      <td>bot.bb7c3624-5ce7-48e0-a317-22662cfae46d@bot.d...</td>\n",
       "      <td>resnet18-label-sug-pretrained-recipe-625d7d47e...</td>\n",
       "      <td>My snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[label-suggest]</td>\n",
       "      <td>{'batch_size': 16, 'start_epoch': 0, 'num_epoc...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-04-18T15:13:54.015Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '625d801a52e3262060...</td>\n",
       "      <td>{'labels': ['Test1', 'Test2', 'Test3'], 'ontol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>625d80483da57ac9545e5caa</td>\n",
       "      <td>bot.bb7c3624-5ce7-48e0-a317-22662cfae46d@bot.d...</td>\n",
       "      <td>resnet18-label-sug-pretrained-recipe-625d7d47e...</td>\n",
       "      <td>My snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>created</td>\n",
       "      <td>[label-suggest]</td>\n",
       "      <td>{'batch_size': 16, 'start_epoch': 0, 'num_epoc...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>{'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...</td>\n",
       "      <td>616d70c57136ca40bca78ad6</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-04-18T15:14:16.022Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '625d80366c3fd58669...</td>\n",
       "      <td>{'labels': ['Test1', 'Test2', 'Test3'], 'ontol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "0    616d70ed451677b35347ee34   \n",
       "1    6280bde54b152c24a698ee26   \n",
       "2    616d70f37136cad9e8a78ad7   \n",
       "3    616ef7be950f5dccfc9e57b8   \n",
       "4    616ef943950f5d2c659e57ba   \n",
       "..                        ...   \n",
       "113  621e24afa7c041a172862d7c   \n",
       "114  621e3948a7c04117cd862d84   \n",
       "115  624ecd80c7e35d6ff5e24d21   \n",
       "116  625d8032ff09e1357a3ad057   \n",
       "117  625d80483da57ac9545e5caa   \n",
       "\n",
       "                                               creator  \\\n",
       "0                                     yair@dataloop.ai   \n",
       "1                                       or@dataloop.ai   \n",
       "2                                     yair@dataloop.ai   \n",
       "3                            pipelines-reg@dataloop.ai   \n",
       "4                            pipelines-reg@dataloop.ai   \n",
       "..                                                 ...   \n",
       "113                              pipelines@dataloop.ai   \n",
       "114                              pipelines@dataloop.ai   \n",
       "115                              pipelines@dataloop.ai   \n",
       "116  bot.bb7c3624-5ce7-48e0-a317-22662cfae46d@bot.d...   \n",
       "117  bot.bb7c3624-5ce7-48e0-a317-22662cfae46d@bot.d...   \n",
       "\n",
       "                                                  name  \\\n",
       "0                                  pretrained-resnet18   \n",
       "1                             sheep-soft-augmentations   \n",
       "2                                  pretrained-resnet50   \n",
       "3    resnet18-label-sug-pretrained-recipe-60350315b...   \n",
       "4    resnet18-label-sug-pretrained-recipe-616be3db4...   \n",
       "..                                                 ...   \n",
       "113  resnet18-label-sug-pretrained-recipe-621e2319c...   \n",
       "114  resnet18-label-sug-pretrained-recipe-621e391d8...   \n",
       "115  resnet18-label-sug-pretrained-recipe-61dc00b54...   \n",
       "116  resnet18-label-sug-pretrained-recipe-625d7d47e...   \n",
       "117  resnet18-label-sug-pretrained-recipe-625d7d47e...   \n",
       "\n",
       "                          description is_global   status  \\\n",
       "0    resnset18 pretrained on imagenet      None  created   \n",
       "1    resnset18 pretrained on imagenet      None  created   \n",
       "2    resnset50 pretrained on imagenet      None  created   \n",
       "3    resnset18 pretrained on imagenet      None  created   \n",
       "4    resnset18 pretrained on imagenet      None  created   \n",
       "..                                ...       ...      ...   \n",
       "113                       My snapshot      None  created   \n",
       "114                       My snapshot      None  created   \n",
       "115                       My snapshot      None  created   \n",
       "116                       My snapshot      None  created   \n",
       "117                       My snapshot      None  created   \n",
       "\n",
       "                       tags  \\\n",
       "0    [pretrained, imagenet]   \n",
       "1    [pretrained, imagenet]   \n",
       "2    [pretrained, imagenet]   \n",
       "3    [pretrained, imagenet]   \n",
       "4    [pretrained, imagenet]   \n",
       "..                      ...   \n",
       "113         [label-suggest]   \n",
       "114         [label-suggest]   \n",
       "115         [label-suggest]   \n",
       "116         [label-suggest]   \n",
       "117         [label-suggest]   \n",
       "\n",
       "                                         configuration version  \\\n",
       "0    {'weights_filename': 'model.pth', 'classes_fil...   1.0.0   \n",
       "1    {'weights_filename': 'model.pth', 'classes_fil...   1.0.1   \n",
       "2    {'weights_filename': 'model.pth', 'classes_fil...   1.0.0   \n",
       "3    {'weights_filename': 'model.pth', 'classes_fil...   1.0.1   \n",
       "4    {'weights_filename': 'model.pth', 'classes_fil...   1.0.1   \n",
       "..                                                 ...     ...   \n",
       "113  {'batch_size': 16, 'start_epoch': 0, 'num_epoc...   1.0.0   \n",
       "114  {'batch_size': 16, 'start_epoch': 0, 'num_epoc...   1.0.0   \n",
       "115  {'batch_size': 16, 'start_epoch': 0, 'num_epoc...   1.0.0   \n",
       "116  {'batch_size': 16, 'start_epoch': 0, 'num_epoc...   1.0.0   \n",
       "117  {'batch_size': 16, 'start_epoch': 0, 'num_epoc...   1.0.0   \n",
       "\n",
       "                                               context  \\\n",
       "0    {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "1    {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "2    {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "3    {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "4    {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "..                                                 ...   \n",
       "113  {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "114  {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "115  {'org': '7db04660-d106-4ec2-879e-ba48fb0ca2b0'...   \n",
       "116  {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "117  {'org': 'd25cecad-34f7-4e38-9750-bd9a1d387bfd'...   \n",
       "\n",
       "                      modelId                 datasetId  \\\n",
       "0    616d70c57136ca40bca78ad6                      None   \n",
       "1    616d70c57136ca40bca78ad6  6280bda5ea2a6ca88830589b   \n",
       "2    616d70c57136ca40bca78ad6                      None   \n",
       "3    616d70c57136ca40bca78ad6                      None   \n",
       "4    616d70c57136ca40bca78ad6                      None   \n",
       "..                        ...                       ...   \n",
       "113  616d70c57136ca40bca78ad6                      None   \n",
       "114  616d70c57136ca40bca78ad6                      None   \n",
       "115  616d70c57136ca40bca78ad6                      None   \n",
       "116  616d70c57136ca40bca78ad6                      None   \n",
       "117  616d70c57136ca40bca78ad6                      None   \n",
       "\n",
       "                    createdAt  \\\n",
       "0    2021-10-18T13:04:45.480Z   \n",
       "1    2021-10-18T13:04:45.480Z   \n",
       "2    2021-10-18T13:04:51.467Z   \n",
       "3    2021-10-19T16:52:14.537Z   \n",
       "4    2021-10-19T16:58:43.796Z   \n",
       "..                        ...   \n",
       "113  2022-03-01T13:50:39.909Z   \n",
       "114  2022-03-01T15:18:32.709Z   \n",
       "115  2022-04-07T11:39:44.694Z   \n",
       "116  2022-04-18T15:13:54.015Z   \n",
       "117  2022-04-18T15:14:16.022Z   \n",
       "\n",
       "                                                bucket  \\\n",
       "0    {'type': 'gcs', 'gcsProjectName': 'viewo-main'...   \n",
       "1    {'type': 'item', 'itemId': '6280bde4c31b850518...   \n",
       "2    {'type': 'gcs', 'gcsProjectName': 'viewo-main'...   \n",
       "3    {'type': 'item', 'itemId': '616ef7be930c82bada...   \n",
       "4    {'type': 'item', 'itemId': '616ef943930c82bada...   \n",
       "..                                                 ...   \n",
       "113  {'type': 'item', 'itemId': '621e249b4aa3db5d7e...   \n",
       "114  {'type': 'item', 'itemId': '621e39391bdd033c7f...   \n",
       "115  {'type': 'item', 'itemId': '624ecd70c07eba9a96...   \n",
       "116  {'type': 'item', 'itemId': '625d801a52e3262060...   \n",
       "117  {'type': 'item', 'itemId': '625d80366c3fd58669...   \n",
       "\n",
       "                                          ontologySpec  \n",
       "0    {'labels': ['tench', 'goldfish', 'great white ...  \n",
       "1    {'labels': ['tench', 'goldfish', 'great white ...  \n",
       "2    {'labels': ['tench', 'goldfish', 'great white ...  \n",
       "3    {'labels': ['tench', 'goldfish', 'great white ...  \n",
       "4    {'labels': ['tench', 'goldfish', 'great white ...  \n",
       "..                                                 ...  \n",
       "113               {'labels': [], 'ontologyId': 'null'}  \n",
       "114  {'labels': ['Test', 'Test2'], 'ontologyId': 'n...  \n",
       "115  {'labels': ['dog', 'eye', 'as', 's', 'aaaaaaa'...  \n",
       "116  {'labels': ['Test1', 'Test2', 'Test3'], 'ontol...  \n",
       "117  {'labels': ['Test1', 'Test2', 'Test3'], 'ontol...  \n",
       "\n",
       "[118 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = dl.models.get(model_name='ResNet')\n",
    "snapshot = model.snapshots.get('pretrained-resnet18')\n",
    "model.snapshots.list().to_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pretrained Model  \n",
    "We will \"build\" to model adapter to get the model code locally and the create an instance of the ModelAdapter class.  \n",
    "After that, we load the pretrained snapshot into the model adapter.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\shabtay\\fonda\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "adapter = model.build()\n",
    "adapter.load_from_snapshot(snapshot=snapshot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an item and predict with upload.  \n",
    "You can also open the item in the platform to view and edit annotations easily.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dl.items.get(item_id='611e174e4c09acc3c5bb81d3')\n",
    "annotations = adapter.predict_items([item], with_upload=True)\n",
    "image = np.asarray(Image.open(item.download()))\n",
    "plt.imshow(item.annotations.show(image,\n",
    "                                 thickness=5))\n",
    "print('Classification: {}'.format(annotations[0][0].label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on new dataset  \n",
    "We will use a public sheep face dataset. We create a project and a dataset and upload the data with 4 labels of sheep.  \n",
    "NOTE: You might need to change the location of the items (should point to the root of the documentation repository)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\shabtay\\fonda\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "project = dl.projects.get('Sheep Face - Model Mgmt')\n",
    "dataset = project.datasets.get('Sheep Face')\n",
    "# dataset.to_df()\n",
    "# _ = dataset.items.upload(local_path='../../../../assets/sample_datasets/SheepFace/items/*',\n",
    "#                          local_annotations_path='../../../../assets/sample_datasets/SheepFace/json')\n",
    "# dataset.add_labels(label_list=['Marino', 'Poll Dorset', 'Suffolk', 'White Suffolk'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the \"prepare_dataset\" method. This will clone and freeze the dataset (so that we'll be able to reproduce the training and keep a snapshot of the data).  \n",
    "The cloned dataset will be split into subsets (using DQL or percentage). In this examples, we'll use a 80/20 train validation split.  \n",
    "After that we clone the pretrained snapshot to have a starting point for the fine-tuning.  \n",
    "The snapshot's configuration will determine some runtime configurations, for instance, we will train for only 2 epochs.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-15 13:15:30][WAR][dtlpy:v1.57.10][ml.train_utils:37] Cloned dataset already exist. Using it...\n"
     ]
    }
   ],
   "source": [
    "partitions = {dl.SnapshotPartitionType.TRAIN: 0.8,\n",
    "              dl.SnapshotPartitionType.VALIDATION: 0.2}\n",
    "cloned_dataset = train_utils.prepare_dataset(dataset,\n",
    "                                             filters=None,\n",
    "                                             partitions=partitions)\n",
    "snapshot_name = 'sheep-soft-augmentations'\n",
    "# create an Item Bucket to save snapshot in your project\n",
    "# bucket = project.buckets.create(bucket_type=dl.BucketType.ITEM,\n",
    "#                                 model_name=model.name,\n",
    "#                                 snapshot_name=snapshot_name)\n",
    "# new_snapshot = snapshot.clone(snapshot_name=snapshot_name,\n",
    "#                               dataset_id=cloned_dataset.id,\n",
    "#                               project_id=project.id,\n",
    "#                               bucket=bucket,\n",
    "#                               configuration={'batch_size': 16,\n",
    "#                                              'start_epoch': 0,\n",
    "#                                              'num_epochs': 2,\n",
    "#                                              'input_size': 256,\n",
    "#                                              'id_to_label_map': {(v - 1): k for k, v in\n",
    "#                                                                  dataset.instance_map.items()}\n",
    "#                                              },\n",
    "                              \n",
    "#                              )\n",
    "new_snapshot = project.snapshots.get(snapshot_name=snapshot_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the new un-trained snapshot to the adapter and prepare the training local dataset  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-15 13:16:03][WAR][dtlpy:v1.57.10][ml.base_model_adapter:66] Replacing snapshot from 'pretrained-resnet18' to 'sheep-soft-augmentations'\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:38<00:00,  2.61it/s]\n",
      "[2022-05-15 13:16:45][WAR][dtlpy:v1.57.10][entities.item:108] Item has been fetched from a dataset that is not belong to it\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1344 [00:00<?, ?it/s]\n",
      "  0%|▏                                                                                                                                                                                                   | 1/1344 [00:00<04:27,  5.03it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                   | 1/2 [00:00<00:00,  4.72it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.07it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1344/1344 [00:23<00:00, 57.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.40it/s]\n",
      "[2022-05-15 13:17:24][WAR][dtlpy:v1.57.10][entities.item:108] Item has been fetched from a dataset that is not belong to it\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s]\n",
      "  0%|                                                                                                                                                                                                             | 0/336 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                                               | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.79it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [00:06<00:00, 53.25it/s]\n",
      "[2022-05-15 13:17:31][WAR][dtlpy:v1.57.10][repositories.downloader:144] No items found! Nothing was downloaded\n"
     ]
    }
   ],
   "source": [
    "adapter.load_from_snapshot(snapshot=new_snapshot)\n",
    "root_path, data_path, output_path = adapter.prepare_training()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start The Train  \n",
    "Now We have the model, the snapshot, and the data ready. We are ready to train.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-15 13:17:36][WAR][dtlpy:v1.57.10][repositories.recipes:159] Deprecation Warning - return type will be pageEntity from version 1.46.0 not a list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 'ResNet' with snapshot '6280d25491ba780d27ac6dc3' on data 'C:\\\\Users\\\\Shabtay\\\\.dataloop\\\\training\\\\6280d25491ba780d27ac6dc3_sheep-soft-augmentations\\\\2022-05-15-131605\\\\datasets\\\\6280c489e72e76a6d35e4c51'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-15 13:17:36][WAR][dtlpy:v1.57.10][repositories.ontologies:230] Deprecation Warning - return type will be pageEntity from version 1.46.0 not a list\n",
      "Loading Data Generator: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1344/1344 [00:00<00:00, 3068.70it/s]\n",
      "Loading Data Generator: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [00:00<00:00, 3574.53it/s]\n",
      "  0%|                                                                                                                                                                                                           | 0/84 [00:00<?, ?batch/s]e:\\shabtay\\fonda\\venv\\lib\\site-packages\\imgaug\\imgaug.py:145: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  return isinstance(val, collections.Iterable)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:11<00:00,  7.16batch/s, accuracy=59.5, loss=0.969]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 21.69batch/s, accuracy=80.7, loss=0.527]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:08<00:00,  9.71batch/s, accuracy=85.4, loss=0.46]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 22.33batch/s, accuracy=86.6, loss=0.351]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training {!r} with snapshot {!r} on data {!r}\".format(model.name, new_snapshot.id, data_path))\n",
    "adapter.train(data_path=data_path,\n",
    "              output_path=output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Snapshot  \n",
    "We will save the locally-trained snapshot and upload the trained weights to the Item Bucket.  \n",
    "This will ensure we have everything in the Dataloop platform and everyone can use our trained snapshot.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                                                                                                                                         | 0.00/42.7M [00:00<?, ?B/s]\u001b[A\n",
      "  0%|▎                                                                                                                                                                                                | 64.0k/42.7M [00:00<07:21, 101kB/s]\u001b[A\n",
      "  0%|▊                                                                                                                                                                                                 | 192k/42.7M [00:00<02:22, 312kB/s]\u001b[A\n",
      "  1%|█▍                                                                                                                                                                                                | 320k/42.7M [00:00<01:47, 414kB/s]\u001b[A\n",
      "  1%|█▉                                                                                                                                                                                                | 448k/42.7M [00:01<01:17, 569kB/s]\u001b[A\n",
      "  2%|███▋                                                                                                                                                                                             | 832k/42.7M [00:01<00:34, 1.27MB/s]\u001b[A\n",
      "  4%|██████▋                                                                                                                                                                                         | 1.50M/42.7M [00:01<00:16, 2.62MB/s]\u001b[A\n",
      "  7%|█████████████▏                                                                                                                                                                                  | 2.94M/42.7M [00:01<00:07, 5.48MB/s]\u001b[A\n",
      " 14%|██████████████████████████                                                                                                                                                                      | 5.81M/42.7M [00:01<00:03, 11.3MB/s]\u001b[A\n",
      " 17%|███████████████████████████████▋                                                                                                                                                                | 7.06M/42.7M [00:01<00:03, 11.7MB/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████████████▍                                                                                                                                         | 12.1M/42.7M [00:01<00:01, 22.8MB/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████████████▍                                                                                                                              | 14.6M/42.7M [00:01<00:01, 20.1MB/s]\u001b[A\n",
      " 39%|███████████████████████████████████████████████████████████████████████████▎                                                                                                                    | 16.8M/42.7M [00:02<00:01, 16.7MB/s]\u001b[A\n",
      " 44%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                            | 18.6M/42.7M [00:02<00:01, 14.6MB/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 20.2M/42.7M [00:02<00:01, 13.2MB/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                              | 21.7M/42.7M [00:02<00:01, 12.7MB/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 23.0M/42.7M [00:02<00:01, 12.8MB/s]\u001b[A\n",
      " 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                  | 24.3M/42.7M [00:02<00:01, 12.1MB/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 25.6M/42.7M [00:02<00:01, 12.0MB/s]\u001b[A\n",
      " 63%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                       | 26.8M/42.7M [00:03<00:01, 11.9MB/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 28.1M/42.7M [00:03<00:01, 12.1MB/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 29.3M/42.7M [00:03<00:01, 11.7MB/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 30.5M/42.7M [00:03<00:01, 11.8MB/s]\u001b[A\n",
      " 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                 | 31.7M/42.7M [00:03<00:00, 11.7MB/s]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 32.9M/42.7M [00:03<00:00, 11.8MB/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 34.1M/42.7M [00:03<00:00, 11.7MB/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 35.2M/42.7M [00:03<00:00, 11.7MB/s]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                            | 36.4M/42.7M [00:03<00:00, 11.7MB/s]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 37.5M/42.7M [00:03<00:00, 11.7MB/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 38.7M/42.7M [00:04<00:00, 11.7MB/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 39.8M/42.7M [00:04<00:00, 11.7MB/s]\u001b[A\n",
      " 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 40.9M/42.7M [00:04<00:00, 11.7MB/s]\u001b[A\n",
      "42.8MB [00:05, 7.97MB/s]                                                                                                                                                                                                                  \u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.05s/it]\n"
     ]
    }
   ],
   "source": [
    "adapter.save_to_snapshot(local_path=output_path,\n",
    "                         replace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list our bucket's content, and add more files that are needed for loading/running the snapshot  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotated</th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>hidden</th>\n",
       "      <th>dir</th>\n",
       "      <th>annotationsCount</th>\n",
       "      <th>dataset</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>/artifacts/models/ResNet/snapshots/sheep-soft-...</td>\n",
       "      <td>model.pth</td>\n",
       "      <td>file</td>\n",
       "      <td>6280d3667c2e42d85a538c94</td>\n",
       "      <td>False</td>\n",
       "      <td>/artifacts/models/ResNet/snapshots/sheep-soft-...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://rc-gate.dataloop.ai/api/v1/datasets/62...</td>\n",
       "      <td>2022-05-15T10:18:14.000Z</td>\n",
       "      <td>6280c4509a7b5c46d4632ee9</td>\n",
       "      <td>or@dataloop.ai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotated                                           filename       name  \\\n",
       "0      False  /artifacts/models/ResNet/snapshots/sheep-soft-...  model.pth   \n",
       "\n",
       "   type                        id  hidden  \\\n",
       "0  file  6280d3667c2e42d85a538c94   False   \n",
       "\n",
       "                                                 dir  annotationsCount  \\\n",
       "0  /artifacts/models/ResNet/snapshots/sheep-soft-...                 0   \n",
       "\n",
       "                                             dataset  \\\n",
       "0  https://rc-gate.dataloop.ai/api/v1/datasets/62...   \n",
       "\n",
       "                  createdAt                 datasetId         creator  \n",
       "0  2022-05-15T10:18:14.000Z  6280c4509a7b5c46d4632ee9  or@dataloop.ai  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter.snapshot.bucket.list_content().to_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict On Our New Trained Snapshot  \n",
    "We will load our snapshot and visualize some items' predictions  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\shabtay\\fonda\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "[2022-05-15 13:18:33][ERR][dtlpy:v1.57.10][services.api_client:1327] [Response <404>][Reason: Not Found][Text: {\"statusCode\":404,\"message\":\"item not found\"}]\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "('404', 'item not found')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-33615d050c2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'611e174e4c09acc3c5bb81d3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mannotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_upload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m plt.imshow(item.annotations.show(np.asarray(image),\n\u001b[0;32m      5\u001b[0m                                  thickness=5))\n",
      "\u001b[1;32me:\\shabtay\\fonda\\venv\\lib\\site-packages\\dtlpy\\repositories\\items.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, filepath, item_id, fetch, is_dir)\u001b[0m\n\u001b[0;32m    259\u001b[0m                                 item.filename))\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPlatformException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                 \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFilters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\shabtay\\fonda\\venv\\lib\\site-packages\\dtlpy\\exceptions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, error, message)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnknownException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFound\u001b[0m: ('404', 'item not found')"
     ]
    }
   ],
   "source": [
    "item = dl.items.get(item_id='611e174e4c09acc3c5bb81d3')\n",
    "annotations = adapter.predict_items([item], with_upload=True)\n",
    "image = Image.open(item.download())\n",
    "plt.imshow(item.annotations.show(np.asarray(image),\n",
    "                                 thickness=5))\n",
    "print('Classification: {}'.format(annotations[0][0].label))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
