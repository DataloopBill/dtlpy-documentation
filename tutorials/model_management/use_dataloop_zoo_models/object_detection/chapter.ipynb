{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Training an object detection model with YOLOv5  \n", "In this tutorial we will use the YOLOv5 Model Adapter to train and inference on custom data.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "from PIL import Image\n", "import numpy as np\n", "import dtlpy as dl\n", "from dtlpy.ml import train_utils\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create the Package and pretrained model in your project  \n", "We start by creating the entities in our project. The model codebase is in our public github.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "filters = dl.Filters(resource=dl.FiltersResource.MODEL)\n", "filters.add(field='name', values='yolo-v5')\n", "filters.add(field='scope', values='public')\n", "models = dl.models.list(filters=filters)\n", "models.to_df()\n", "model = models.items[0]\n", "snapshot = model.snapshots.get('pretrained-yolo-v5-small')\n", "model.snapshots.list().to_df()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Run the pretrained Model  \n", "We will \"build\" to the model adapter to get the model code locally and then create an instance of the ModelAdapter class.  \n", "After that, we load the pretrained model into the model adapter.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter = model.build()\n", "adapter.load_from_snapshot(snapshot=snapshot)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get an item and predict with upload.  \n", "You can also open the item in the platform to view and edit annotations easily.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item = dl.items.get(item_id='611e174e4c09acc3c5bb81d3')\n", "annotations = adapter.predict_items([item], with_upload=True)\n", "image = np.asarray(Image.open(item.download()))\n", "plt.imshow(item.annotations.show(image,\n", "                                 thickness=5))\n", "print('Classes found: {}'.format([ann.label for ann in annotations[0]]))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train on new dataset  \n", "We will use a public fruits dataset. We create a project and a dataset and upload the data with 3 labels of fruit.  \n", "NOTE: You might need to change the location of the items (should point to the root of the documentation repository)  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["project = dl.projects.create('Fruit - Model Mgmt')\n", "dataset = project.datasets.create('Fruit')\n", "dataset.to_df()\n", "_ = dataset.items.upload(local_path='../../../../assets/sample_datasets/FruitImage/items/*',\n", "                         local_annotations_path='../../../../assets/sample_datasets/FruitImage/json')\n", "dataset.add_labels(label_list=['orange', 'banana', 'apple'])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we'll run the \"prepare_dataset\" method. This will clone and freeze the dataset (so that we'll be able to reproduce the training and keep a snapshot of the data).  \n", "The cloned dataset will be split into subsets (using DQL or percentage). In this example, we'll use a 80/20 train validation split.  \n", "After that we clone the pretrained model to have a starting point for the fine-tuning.  \n", "The model's configuration will determine some runtime configurations, for instance, we will train for only 2 epochs.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["partitions = {dl.SnapshotPartitionType.TRAIN: 0.8,\n", "              dl.SnapshotPartitionType.VALIDATION: 0.2}\n", "cloned_dataset = train_utils.prepare_dataset(dataset,\n", "                                             filters=None,\n", "                                             partitions=partitions)\n", "snapshot_name = 'fruits'\n", "# create an Item Bucket to save snapshot in your project\n", "bucket = project.buckets.create(bucket_type=dl.BucketType.ITEM,\n", "                                model_name=model.name,\n", "                                snapshot_name=snapshot_name)\n", "new_snapshot = snapshot.clone(snapshot_name=snapshot_name,\n", "                              dataset_id=cloned_dataset.id,\n", "                              project_id=project.id,\n", "                              bucket=bucket,\n", "                              labels=list(dataset.instance_map.keys()),\n", "                              configuration={'batch_size': 16,\n", "                                             'start_epoch': 0,\n", "                                             'num_epochs': 2,\n", "                                             'input_size': 256,\n", "                                             'data_yaml_fname': 'data.yaml',\n", "                                             'hyp_yaml_fname': 'hyp.finetune.yaml',\n", "                                             'id_to_label_map': {(v - 1): k for k, v in\n", "                                                                 dataset.instance_map.items()}\n", "                                             })\n", "", "new_snapshot = model.snapshots.get(snapshot_name=snapshot_name)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll load the new un-trained model to the adapter and prepare the training local dataset  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter.load_from_snapshot(snapshot=new_snapshot)\n", "root_path, data_path, output_path = adapter.prepare_training()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Start the training  \n", "Now we have the package, model, and data ready. We are ready to train!  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["print(\"Training {!r} with snapshot {!r} on data {!r}\".format(model.name, new_snapshot.id, data_path))\n", "", "adapter.train(data_path=data_path,\n", "              output_path=output_path)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Save the model  \n", "We will save the locally-trained model and upload the trained weights to the Item Bucket.  \n", "This will ensure we have everything in the Dataloop platform and everyone can use our trained model.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter.save_to_snapshot(local_path=output_path,\n", "                         replace=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can also list our bucket's content, and add more files that are needed for loading/running the model  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["adapter.snapshot.bucket.list_content()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Predict with on newly trained model  \n", "We will load our model and view the predictions for some items.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item = dl.items.get(item_id='611e174e4c09acc3c5bb81d3')\n", "annotations = adapter.predict_items([item], with_upload=True)\n", "", "image = Image.open(item.download())\n", "plt.imshow(item.annotations.show(np.asarray(image),\n", "                                 thickness=5))\n", "print('Classification: {}'.format(annotations[0][0].label))\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}