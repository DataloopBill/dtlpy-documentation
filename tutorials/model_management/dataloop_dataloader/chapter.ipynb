{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Dataloop Dataloader  \n", "A dl.Dataset image and annotation generator for training and for items visualization  \n", "  \n", "We can visualize the data with augmentation for debug and exploration.  \n", "After that, we will use the Data Generator as an input to the training functions  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["from dtlpy.utilities import DatasetGenerator\n", "import dtlpy as dl\n", "dataset = dl.datasets.get(dataset_id='611b86e647fe2f865323007a')\n", "dataloader = DatasetGenerator(data_path='train',\n", "                              dataset_entity=dataset,\n", "                              annotation_type=dl.AnnotationType.BOX)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Object Detection Examples  \n", "We can visualize a random item from the dataset:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["for i in range(5):\n", "    dataloader.visualize()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Or get the same item using it's index:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["for i in range(5):\n", "    dataloader.visualize(10)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Adding augmentations using imgaug repository:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["from imgaug import augmenters as iaa\n", "import numpy as np\n", "", "augmentation = iaa.Sequential([\n", "    iaa.Resize({\"height\": 256, \"width\": 256}),\n", "    # iaa.Superpixels(p_replace=(0, 0.5), n_segments=(10, 50)),\n", "    iaa.flip.Fliplr(p=0.5),\n", "    iaa.flip.Flipud(p=0.5),\n", "    iaa.GaussianBlur(sigma=(0.0, 0.8)),\n", "])\n", "tfs = [\n", "    augmentation,\n", "    np.copy,\n", "    # transforms.ToTensor()\n", "]\n", "", "dataloader = DatasetGenerator(data_path='train',\n", "                              dataset_entity=dataset,\n", "                              annotation_type=dl.AnnotationType.BOX,\n", "                              transforms=tfs)\n", "dataloader.visualize()\n", "dataloader.visualize(10)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["All of the Data Generator options (from the function docstring):  \n", "  \n", ":param dataset_entity: dl.Dataset entity  \n", ":param annotation_type: dl.AnnotationType - type of annotation to load from the annotated dataset  \n", ":param filters: dl.Filters - filtering entity to filter the dataset items  \n", ":param data_path: Path to Dataloop annotations (root to \"item\" and \"json\").  \n", ":param overwrite:  \n", ":param label_to_id_map: dict - {label_string: id} dictionary  \n", ":param transforms: Optional transform to be applied on a sample. list or torchvision.Transform  \n", ":param num_workers:  \n", ":param shuffle: Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.  \n", ":param seed: Optional random seed for shuffling and transformations.  \n", ":param to_categorical: convert label id to categorical format  \n", ":param class_balancing: if True - performing random over-sample with class ids as the target to balance training data  \n", ":param return_originals: bool - If True, return ALSO images and annotations before transformations (for debug)  \n", ":param ignore_empty: bool - If True, generator will NOT collect items without annotations  \n", "  \n", "  \n", "The output of a single element is a dictionary holding all the relevant informtaion.  \n", "the keys for the DataGen above are: ['image_filepath', 'item_id', 'box', 'class', 'labels', 'annotation_filepath', 'image', 'annotations', 'orig_image', 'orig_annotations']  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["print(list(dataloader[0].keys()))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll add the flag to return the origin items to understand better how the augmentations look like.  \n", "Let's set the flag and we can plot:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "dataloader = DatasetGenerator(data_path='train',\n", "                              dataset_entity=dataset,\n", "                              annotation_type=dl.AnnotationType.BOX,\n", "                              return_originals=True,\n", "                              shuffle=False,\n", "                              transforms=tfs)\n", "fig, ax = plt.subplots(2, 2)\n", "", "for i in range(2):\n", "    item_element = dataloader[np.random.randint(len(dataloader))]\n", "    ax[i, 0].imshow(item_element['image'])\n", "    ax[i, 0].set_title('After Augmentations')\n", "    ax[i, 1].imshow(item_element['orig_image'])\n", "    ax[i, 1].set_title('Before Augmentations')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Segmentation Examples  \n", "First we'll load a semantic dataset and view some images and the output structure  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["dataset = dl.datasets.get(dataset_id='6197985a104eb81cb728e4ac')\n", "dataloader = DatasetGenerator(data_path='semantic',\n", "                              dataset_entity=dataset,\n", "                              transforms=tfs,\n", "                              return_originals=True,\n", "                              annotation_type=dl.AnnotationType.SEGMENTATION)\n", "for i in range(5):\n", "    dataloader.visualize()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visualize original vs augmented image and annotations mask:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(2, 4)\n", "for i in range(2):\n", "    item_element = dataloader[np.random.randint(len(dataloader))]\n", "    ax[i, 0].imshow(item_element['orig_image'])\n", "    ax[i, 0].set_title('Original Image')\n", "    ax[i, 1].imshow(item_element['orig_annotations'])\n", "    ax[i, 1].set_title('Original Annotations')\n", "    ax[i, 2].imshow(item_element['image'])\n", "    ax[i, 2].set_title('Augmented Image')\n", "    ax[i, 3].imshow(item_element['annotations'])\n", "    ax[i, 3].set_title('Augmented Annotations')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Converting to 3d one-hot to visualize the binary mask per label. We will plot only 8 label (there might be more on the item):  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item_element = dataloader[np.random.randint(len(dataloader))]\n", "annotations = item_element['annotations']\n", "unique_labels = np.unique(annotations)\n", "one_hot_annotations = np.arange(len(dataloader.id_to_label_map)) == annotations[..., None]\n", "print('unique label indices in the item: {}'.format(unique_labels))\n", "print('unique labels in the item: {}'.format([dataloader.id_to_label_map[i] for i in unique_labels]))\n", "plt.figure()\n", "plt.imshow(item_element['image'])\n", "fig = plt.figure()\n", "for i_label_ind, label_ind in enumerate(unique_labels[:8]):\n", "    ax = fig.add_subplot(2, 4, i_label_ind + 1)\n", "    ax.imshow(one_hot_annotations[:, :, label_ind])\n", "    ax.set_title(dataloader.id_to_label_map[label_ind])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["batch_size and collate_fn  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# batchsize and collate\n", "...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["label mapping and default background  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["dataset = dl.datasets.get(dataset_id='6197985a104eb81cb728e4ac')\n", "label_to_id_map = {'cat': 1,\n", "                   'dog': 1,\n", "                   '$default': 0}\n", "dataloader = DatasetGenerator(data_path='semantic',\n", "                              dataset_entity=dataset,\n", "                              transforms=tfs,\n", "                              return_originals=True,\n", "                              label_to_id_map=label_to_id_map,\n", "                              annotation_type=dl.AnnotationType.SEGMENTATION)\n", "for i in range(5):\n", "    dataloader.visualize()\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}