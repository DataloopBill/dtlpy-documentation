{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train UNet Model\n",
    "\n",
    "In this Notebook you will learn how to train your UNet architecture with Dataloop and Pytorch\n",
    "\n",
    "UNet is an Encoder - Decoder architecture for creating segmentation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import dtlpy as dl\n",
    "from dtlpy.ml import train_utils\n",
    "from dtlpy.ml.dataset_generators.torch_dataset_generator import DataGenerator\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the DataLoop entities\n",
    "\n",
    "lets get the model and dataset entities from our dataloop platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dl.models.get('unet')  # This is the global model\n",
    "# Data entities\n",
    "project = dl.projects.get('shefi-contests', '50f0fc03-4d70-455d-b485-c78cca53f2be')\n",
    "dataset = dl.datasets.get('carvana', '61b9bbc1e8ad454a9aa7d285')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snapshot\n",
    "\n",
    "Now we can create a new snapshot - we will add your name and data to the suffix to make the snapshot has a unique name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 09:40:58.832 [WARNING]-[MainThread]-[v1.47.1]dtlpy.repositories.snapshots: Note! you are specified project_id '50f0fc03-4d70-455d-b485-c78cca53f2be' which is different from repository context: None\n",
      "2022-01-03 09:40:59.019 [ERROR]-[MainThread]-[v1.47.1]dtlpy.repositories.snapshots: Snapshot does not support 'unlocked dataset'. Please change 'carvana' to readonly\n"
     ]
    }
   ],
   "source": [
    "whoami = dl.client_api.info()['user_email']\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Create a new snapshot - personally and with currect datetime\n",
    "snapshot_name = f\"carvana-train-example-{whoami.split('@')[0]}-{now.isoformat(timespec='minutes')}\"\n",
    "snapshot = model.snapshots.create(\n",
    "    snapshot_name=snapshot_name,\n",
    "    dataset_id=dataset.id,\n",
    "    description='train unet example',\n",
    "    bucket=project.buckets.create(bucket_type=dl.BucketType.ITEM, model_name=model.name, snapshot_name=snapshot_name),\n",
    "    tags=['example', 'notebook'],\n",
    "    configuration={'id_to_label_map': {'1': 'car'}, 'image_normalize_mu': 0, 'image_normalize_std': 1, 'input_shape': [640, 960]},\n",
    "    project_id=project.id,\n",
    "    labels=['car']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets View the Model and Snapshot entities\n",
    "\n",
    "We use the to_df in order to convert to a DataFrame and view it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creator</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>version</th>\n",
       "      <th>tags</th>\n",
       "      <th>inputType</th>\n",
       "      <th>outputType</th>\n",
       "      <th>projectId</th>\n",
       "      <th>entryPoint</th>\n",
       "      <th>className</th>\n",
       "      <th>codebase</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619d001117bf2dab2b6aa4c3</td>\n",
       "      <td>yair@dataloop.ai</td>\n",
       "      <td>unet</td>\n",
       "      <td>Global Dataloop U-net implemented in pytorch</td>\n",
       "      <td>1.0.1</td>\n",
       "      <td>[torch, unet, semantic]</td>\n",
       "      <td>image</td>\n",
       "      <td>binary</td>\n",
       "      <td>296bc0d5-46fc-447f-b3ee-25899e7268bc</td>\n",
       "      <td>unet_adapter.py</td>\n",
       "      <td>UNetAdapter</td>\n",
       "      <td>{'type': 'git', 'gitUrl': 'https://github.com/...</td>\n",
       "      <td>2021-11-23T14:52:01.787Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id           creator  name                                   description version                     tags inputType outputType                             projectId  \\\n",
       "0  619d001117bf2dab2b6aa4c3  yair@dataloop.ai  unet  Global Dataloop U-net implemented in pytorch   1.0.1  [torch, unet, semantic]     image     binary  296bc0d5-46fc-447f-b3ee-25899e7268bc   \n",
       "\n",
       "        entryPoint    className                                           codebase                 createdAt  \n",
       "0  unet_adapter.py  UNetAdapter  {'type': 'git', 'gitUrl': 'https://github.com/...  2021-11-23T14:52:01.787Z  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creator</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>is_global</th>\n",
       "      <th>status</th>\n",
       "      <th>tags</th>\n",
       "      <th>configuration</th>\n",
       "      <th>modelId</th>\n",
       "      <th>projectId</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>bucket</th>\n",
       "      <th>ontologySpec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61d2a88a275d078c4b370427</td>\n",
       "      <td>yair@dataloop.ai</td>\n",
       "      <td>carvana-train-example-yair-2022-01-03T09:40</td>\n",
       "      <td>train unet example</td>\n",
       "      <td>False</td>\n",
       "      <td>created</td>\n",
       "      <td>[example, notebook]</td>\n",
       "      <td>{'id_to_label_map': {'1': 'car'}, 'image_norma...</td>\n",
       "      <td>619d001117bf2dab2b6aa4c3</td>\n",
       "      <td>50f0fc03-4d70-455d-b485-c78cca53f2be</td>\n",
       "      <td>61b9bbc1e8ad454a9aa7d285</td>\n",
       "      <td>2022-01-03T07:40:58.895Z</td>\n",
       "      <td>{'type': 'item', 'itemId': '61d2a88a80d978833d...</td>\n",
       "      <td>{'labels': ['car'], 'ontologyId': 'null'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id           creator                                         name         description  is_global   status                 tags  \\\n",
       "0  61d2a88a275d078c4b370427  yair@dataloop.ai  carvana-train-example-yair-2022-01-03T09:40  train unet example      False  created  [example, notebook]   \n",
       "\n",
       "                                       configuration                   modelId                             projectId                 datasetId                 createdAt  \\\n",
       "0  {'id_to_label_map': {'1': 'car'}, 'image_norma...  619d001117bf2dab2b6aa4c3  50f0fc03-4d70-455d-b485-c78cca53f2be  61b9bbc1e8ad454a9aa7d285  2022-01-03T07:40:58.895Z   \n",
       "\n",
       "                                              bucket                               ontologySpec  \n",
       "0  {'type': 'item', 'itemId': '61d2a88a80d978833d...  {'labels': ['car'], 'ontologyId': 'null'}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One last thing to make sure before we train\n",
    "\n",
    "Our `adapter` train method expects the data to be organized as: train-validation-test  \n",
    "this can be created manually on small datasets using `train_utils.create_dataset_partition()`\n",
    "\n",
    "Our dataset is already prepared, we will just verify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carvana Data partition, TRAIN: 4070, VALIDATION 1018, TEST 0 \n"
     ]
    }
   ],
   "source": [
    "train_items = dataset.get_partitions(partitions=dl.SnapshotPartitionType.TRAIN)\n",
    "val_items = dataset.get_partitions(partitions=dl.SnapshotPartitionType.VALIDATION)\n",
    "test_items = dataset.get_partitions(partitions=dl.SnapshotPartitionType.TEST)\n",
    "\n",
    "print(f\"Dataset {dataset.name} Data partition, TRAIN: {train_items.items_count}, VALIDATION {val_items.items_count}, TEST {test_items.items_count} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we can start to train\n",
    "\n",
    "We initialize the adapter using the `build` method.\n",
    "\n",
    "The `Adapter` is the base class to connect between dataloop platform and our specific model  \n",
    "some method are inheritance from the base adapter and some are written specifically per model\n",
    "each architecture has it's own adapter which you can view it's raw code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = model.build()\n",
    "adapter.load_from_snapshot(snapshot=snapshot)\n",
    "# adapter._set_adapter_handler('DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path, data_path, output_path = adapter.prepare_training()\n",
    "adapter.train(data_path=data_path, output_path=output_path,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### SAVING\n",
    "\n",
    "The current adapter now holds the best model fit for our data.\n",
    "\n",
    "In order to upload the weights and other configurations we need to save our snapshot.  \n",
    "We will use a temp dir - so we save all content to that dir and upload it (other option is to upload all the *`output_path`* which has more runtime files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_dir = tempfile.mkdtemp(prefix=snapshot.name, suffix=now.strftime('%F-%H%M%S'))\n",
    "adapter.save_to_snapshot(local_path=temp_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING THE MODEL - PREDICTION\n",
    "\n",
    "We will use the DataGenerator to view the image (this utility already connects with our dataloop item and annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = DataGenerator(data_path=os.path.join(data_path, 'train'),\n",
    "                        dataset_entity=snapshot.dataset,\n",
    "                        annotation_type=dl.AnnotationType.SEGMENTATION,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example - get 1 entry and visualize it\n",
    "datagen.visualize(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item = dataset[20]\n",
    "data_item"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e234d837eebba94c7397b4e38c0b82bd3e4741cb2c390182a3fb441eaf8f3cd5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
